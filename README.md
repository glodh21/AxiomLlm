A minimal decoder‑only transformer model trained on a single text corpus.
Crafted as a hands‑on experiment to explore self‑attention and training pipelines.
